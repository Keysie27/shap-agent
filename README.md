# ğŸ¤– SHAP-Agent

**SHAP-Agent** is an explainability tool that combines [SHAP](https://github.com/slundberg/shap) values with a language model API to generate clear, human-friendly explanations of machine learning models.

This app is designed to:
- Analyze trained ML models using SHAP (global explanation)
- Convert SHAP summaries into natural language
- Allow users to upload their own models and data
- Include ready-to-use sample models and datasets for testing

## ğŸ—‚ï¸ Project Structure

shap-agent/
â”‚
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ shap_agent.py                 # GPT-based explanation logic
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py                  # Marks app as a Python package
â”‚   â”œâ”€â”€ main.py                      # Streamlit interface (UI entrypoint)
â”‚   â””â”€â”€ file_handler.py              # Handles uploaded files (models & CSV)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input_data/                  # User-uploaded datasets (.csv)
â”‚   â””â”€â”€ sample_data/                # Sample datasets for testing the app
â”‚       â”œâ”€â”€ logistic_regression.csv
â”‚       â”œâ”€â”€ random_forest.csv
â”‚       â””â”€â”€ xgboost.csv
â”‚
â”œâ”€â”€ input_models/                   # User-uploaded models (.pkl or .joblib)
â”‚
â”œâ”€â”€ sample_models/                  # Pretrained models for demo/testing
â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”œâ”€â”€ random_forest.pkl
â”‚   â””â”€â”€ xgboost.pkl
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agent.py               # Unit tests for GPT logic
â”‚   â”œâ”€â”€ test_file_handler.py        # Tests for file loading
â”‚   â””â”€â”€ test_shap_explainer.py      # Tests for SHAP explanations
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ shap_explainer.py           # SHAP logic (creates summaries per model type)
â”‚
â”œâ”€â”€ .env                            # OpenAI API key and other env variables
â”œâ”€â”€ .gitignore                      # Ignore venv, .env, models, data, etc.
â”œâ”€â”€ README.md                       # Full documentation for using and running the app
â””â”€â”€ requirements.txt                # Python dependencies

## ğŸš€ How to Use

### ğŸ”§ Run Locally

1. **Clone the repo**
```bash
git clone https://github.com/keysie27/shap-agent.git
cd shap-agent
```

2. **Create a virtual environment (optional)**
```bash
python -m venv venv
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

Install and start Ollama If you want to use a free, local agent:

Download and install Ollama from https://ollama.com/download

Then, run: 
```bash
ollama run mistral
```

4. **Environment Setup**

#### `.env` File
Create a `.env` file in the root of the project. This file stores secrets and api configuration values required. 
**Note:** An example `.env` file is available in the `tests/` directory to guide you. Make sure you set all the required variables.

5. **Run the app**
```bash
PYTHONPATH=. streamlit run app/main.py
```

## ğŸ§ª Sample Usage
Use the models and datasets included in:

models/sample_models/
data/sample_data/

These are fully compatible with SHAP and can be used to test the app without uploading anything!

## ğŸ“¥ For End Users

Users can:

- Upload their own models (.pkl or .joblib) to input_models/
- Upload matching datasets (.csv) to data/input_data/
- The app will run SHAP explainability and provide a GPT-based natural language explanation of model behavior.

## ğŸ’¡ Notes on Agents
By default, this project uses Ollama with Mistral, which is:

- Free
- Runs locally on your machine (no API costs)
- Works offline

You can change to other agents later by modifying AGENT_PROVIDER in your .env.

## ğŸ™Œ Credits
- SHAP by Scott Lundberg et al.
- Ollama & Mistral by community contributors
- Streamlit
